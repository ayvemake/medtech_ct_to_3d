{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import monai.transforms as mt\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    ScaleIntensity,\n",
    "    ToTensor\n",
    ")\n",
    "\n",
    "class HEDNet(nn.Module):\n",
    "    \"\"\"HED Network optimisé pour les CT-scans\"\"\"\n",
    "    def __init__(self):\n",
    "        super(HEDNet, self).__init__()\n",
    "        \n",
    "        # Couches de convolution spécialisées pour CT-scans\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Sorties latérales avec attention\n",
    "        self.side1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, 1),\n",
    "            nn.BatchNorm2d(1)\n",
    "        )\n",
    "        \n",
    "        self.side2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 1, 1),\n",
    "            nn.BatchNorm2d(1)\n",
    "        )\n",
    "        \n",
    "        self.side3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 1, 1),\n",
    "            nn.BatchNorm2d(1)\n",
    "        )\n",
    "        \n",
    "        # Fusion avec poids adaptatifs\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Conv2d(3, 1, 1),\n",
    "            nn.BatchNorm2d(1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        c1 = self.conv1(x)\n",
    "        c2 = self.conv2(c1)\n",
    "        c3 = self.conv3(c2)\n",
    "        \n",
    "        # Side outputs avec attention aux bords\n",
    "        s1 = self.side1(c1)\n",
    "        s2 = F.interpolate(self.side2(c2), size=x.shape[2:], mode='bilinear', align_corners=True)\n",
    "        s3 = F.interpolate(self.side3(c3), size=x.shape[2:], mode='bilinear', align_corners=True)\n",
    "        \n",
    "        # Fusion adaptative\n",
    "        fuse = self.fuse(torch.cat([s1, s2, s3], dim=1))\n",
    "        \n",
    "        return torch.sigmoid(fuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumerusDataset:\n",
    "    \"\"\"Class for handling the humerus CT scan dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: Path = Config.DATA_DIR / 'humerus'):\n",
    "        self.data_dir = data_dir\n",
    "        self.series_pattern = \"hum*.dcm\"\n",
    "        self.n_expected_slices = 102\n",
    "    \n",
    "    def load_series(self) -> Tuple[np.ndarray, Dict]:\n",
    "        \"\"\"\n",
    "        Load the complete humerus DICOM series\n",
    "        \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - 3D numpy array of the CT scan\n",
    "            - Dictionary of metadata\n",
    "        \"\"\"\n",
    "        # Get all DICOM files in order\n",
    "        dicom_files = sorted(self.data_dir.glob(self.series_pattern))\n",
    "        \n",
    "        if not dicom_files:\n",
    "            raise FileNotFoundError(f\"No DICOM files found in {self.data_dir}\")\n",
    "        \n",
    "        if len(dicom_files) != self.n_expected_slices:\n",
    "            print(f\"Warning: Found {len(dicom_files)} slices, expected {self.n_expected_slices}\")\n",
    "        \n",
    "        # Load the first slice to get metadata and image dimensions\n",
    "        first_slice = sitk.ReadImage(str(dicom_files[0]))\n",
    "        first_array = sitk.GetArrayFromImage(first_slice)\n",
    "        \n",
    "        # Create volume with correct shape (n_slices, height, width)\n",
    "        volume = np.zeros((len(dicom_files), *first_array.shape[1:]), dtype=np.float32)\n",
    "        \n",
    "        # Load all slices\n",
    "        print(\"Loading DICOM series...\")\n",
    "        for idx, file_path in enumerate(dicom_files):\n",
    "            img = sitk.ReadImage(str(file_path))\n",
    "            slice_array = sitk.GetArrayFromImage(img)[0]  # Get 2D slice\n",
    "            volume[idx] = slice_array\n",
    "        \n",
    "        # Get metadata from first slice\n",
    "        metadata = {\n",
    "            'spacing': first_slice.GetSpacing(),\n",
    "            'origin': first_slice.GetOrigin(),\n",
    "            'direction': first_slice.GetDirection(),\n",
    "            'size': first_slice.GetSize()\n",
    "        }\n",
    "        \n",
    "        # Transpose volume to have shape (height, width, n_slices)\n",
    "        volume = np.transpose(volume, (1, 2, 0))\n",
    "        \n",
    "        return volume, metadata\n",
    "    \n",
    "    def visualize_slices(self, volume: np.ndarray, n_samples: int = 4):\n",
    "        \"\"\"\n",
    "        Visualize sample slices from the volume\n",
    "        \n",
    "        Args:\n",
    "            volume: 3D numpy array of the CT scan\n",
    "            n_samples: Number of slices to visualize\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, n_samples, figsize=(20, 5))\n",
    "        slice_indices = np.linspace(0, volume.shape[2]-1, n_samples, dtype=int)\n",
    "        \n",
    "        for i, idx in enumerate(slice_indices):\n",
    "            axes[i].imshow(volume[:, :, idx], cmap='bone')\n",
    "            axes[i].set_title(f'Slice {idx}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def preprocess_volume(self, volume: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Preprocess the CT volume\n",
    "        \n",
    "        Args:\n",
    "            volume: Raw CT volume\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed volume normalized to [0,1]\n",
    "        \"\"\"\n",
    "        # Convert to HU units (assuming it's not already in HU)\n",
    "        volume_hu = volume.astype(float)\n",
    "        \n",
    "        # Clip to bone window\n",
    "        volume_hu = np.clip(volume_hu, Config.HU_MIN, Config.HU_MAX)\n",
    "        \n",
    "        # Normalize to [0,1]\n",
    "        volume_norm = (volume_hu - Config.HU_MIN) / (Config.HU_MAX - Config.HU_MIN)\n",
    "        \n",
    "        return volume_norm"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
