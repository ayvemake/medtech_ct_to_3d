{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Dict, List\n",
    "import pydicom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VerSe Dataset (Vertèbres)\n",
    "# https://verse2020.grand-challenge.org/\n",
    "\n",
    "# MURA Dataset (Stanford)\n",
    "# https://stanfordmlgroup.github.io/competitions/mura/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataLoader:\n",
    "    def __init__(self, data_dir: Path):\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def load_dicom_series(self, series_dir: Path) -> Tuple[np.ndarray, Dict]:\n",
    "        \"\"\"Charge une série DICOM\"\"\"\n",
    "        # Charger tous les fichiers DICOM\n",
    "        dicom_files = sorted(series_dir.glob('*.dcm'))\n",
    "        \n",
    "        # Lire le premier pour les métadonnées\n",
    "        first_slice = pydicom.dcmread(str(dicom_files[0]))\n",
    "        \n",
    "        # Préparer le volume\n",
    "        volume = np.zeros((first_slice.Rows, first_slice.Columns, len(dicom_files)))\n",
    "        \n",
    "        # Charger chaque tranche\n",
    "        for i, dcm_file in enumerate(dicom_files):\n",
    "            slice_data = pydicom.dcmread(str(dcm_file))\n",
    "            volume[:, :, i] = slice_data.pixel_array\n",
    "        \n",
    "        # Métadonnées importantes\n",
    "        metadata = {\n",
    "            'spacing': (\n",
    "                float(first_slice.PixelSpacing[0]),\n",
    "                float(first_slice.PixelSpacing[1]),\n",
    "                float(first_slice.SliceThickness)\n",
    "            ),\n",
    "            'origin': first_slice.ImagePositionPatient,\n",
    "            'direction': first_slice.ImageOrientationPatient\n",
    "        }\n",
    "        \n",
    "        return volume, metadata\n",
    "\n",
    "    def load_nifti(self, file_path: Path) -> Tuple[np.ndarray, Dict]:\n",
    "        \"\"\"Charge un fichier NIfTI\"\"\"\n",
    "        nifti_img = nib.load(str(file_path))\n",
    "        volume = nifti_img.get_fdata()\n",
    "        \n",
    "        metadata = {\n",
    "            'affine': nifti_img.affine,\n",
    "            'header': dict(nifti_img.header)\n",
    "        }\n",
    "        \n",
    "        return volume, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_volume(dicom_dir: Path) -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"Charge une série DICOM de phalanges avec détection automatique de la taille\"\"\"\n",
    "    print(f\"Loading DICOM series from {dicom_dir}...\")\n",
    "    \n",
    "    # Trouver tous les fichiers phalanx\n",
    "    dicom_files = sorted(dicom_dir.glob('phalanx*.dcm'))\n",
    "    if not dicom_files:\n",
    "        raise FileNotFoundError(f\"No phalanx DICOM files found in {dicom_dir}\")\n",
    "    \n",
    "    print(f\"Found {len(dicom_files)} DICOM files\")\n",
    "    \n",
    "    try:\n",
    "        # Lire le premier fichier pour déterminer la taille\n",
    "        first_file = dicom_files[0]\n",
    "        with open(str(first_file), 'rb') as f:\n",
    "            raw_data = np.fromfile(f, dtype=np.uint16)\n",
    "            \n",
    "        # Calculer les dimensions possibles\n",
    "        total_pixels = len(raw_data)\n",
    "        print(f\"Total pixels in first file: {total_pixels}\")\n",
    "        \n",
    "        # Trouver les facteurs pour déterminer les dimensions possibles\n",
    "        factors = []\n",
    "        for i in range(1, int(np.sqrt(total_pixels)) + 1):\n",
    "            if total_pixels % i == 0:\n",
    "                factors.append((i, total_pixels // i))\n",
    "        \n",
    "        print(\"Possible dimensions:\", factors)\n",
    "        \n",
    "        # Choisir les dimensions les plus proches d'un carré\n",
    "        rows, cols = min(factors, key=lambda x: abs(x[0] - x[1]))\n",
    "        print(f\"Selected dimensions: {rows}x{cols}\")\n",
    "        \n",
    "        # Initialiser le volume\n",
    "        volume = np.zeros((rows, cols, len(dicom_files)))\n",
    "        \n",
    "        # Charger chaque tranche\n",
    "        for i, dcm_file in enumerate(tqdm(dicom_files, desc=\"Loading slices\")):\n",
    "            try:\n",
    "                with open(str(dcm_file), 'rb') as f:\n",
    "                    raw_data = np.fromfile(f, dtype=np.uint16)\n",
    "                    img_array = raw_data.reshape(rows, cols)\n",
    "                volume[:, :, i] = img_array\n",
    "                \n",
    "                # Debug: afficher la première tranche\n",
    "                if i == 0:\n",
    "                    plt.figure(figsize=(10, 10))\n",
    "                    plt.imshow(img_array, cmap='bone')\n",
    "                    plt.title(\"First slice\")\n",
    "                    plt.colorbar()\n",
    "                    plt.show()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nWarning: Error loading {dcm_file.name}: {e}\")\n",
    "                if i > 0:\n",
    "                    volume[:, :, i] = volume[:, :, i-1]\n",
    "                continue\n",
    "        \n",
    "        # Normalisation du volume\n",
    "        volume = volume.astype(float)\n",
    "        volume = (volume - volume.min()) / (volume.max() - volume.min())\n",
    "        \n",
    "        print(f\"\\nVolume loaded successfully!\")\n",
    "        print(f\"Shape: {volume.shape}\")\n",
    "        print(f\"Value range: [{volume.min():.2f}, {volume.max():.2f}]\")\n",
    "        \n",
    "        # Visualiser quelques tranches\n",
    "        visualize_slices(volume)\n",
    "        \n",
    "        return volume, {'spacing': [1.0, 1.0, 1.0]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in load_dicom_volume: {e}\")\n",
    "        raise\n",
    "\n",
    "def visualize_slices(volume: np.ndarray, n_slices: int = 4):\n",
    "    \"\"\"Visualise quelques tranches du volume\"\"\"\n",
    "    fig, axes = plt.subplots(1, n_slices, figsize=(20, 5))\n",
    "    step = volume.shape[2] // n_slices\n",
    "    \n",
    "    for i in range(n_slices):\n",
    "        idx = i * step\n",
    "        axes[i].imshow(volume[:, :, idx], cmap='bone')\n",
    "        axes[i].set_title(f'Slice {idx}')\n",
    "        axes[i].axis('off')\n",
    "        plt.colorbar(axes[i].imshow(volume[:, :, idx], cmap='bone'), ax=axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=100):\n",
    "    \"\"\"Entraînement du modèle\"\"\"\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Mode entraînement\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}')):\n",
    "            data, target = data.to(Config.DEVICE), target.to(Config.DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Visualisation périodique\n",
    "            if batch_idx % 10 == 0:\n",
    "                visualize_batch(data, target, output, epoch, batch_idx)\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Mode validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        dice_scores = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(Config.DEVICE), target.to(Config.DEVICE)\n",
    "                output = model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "                \n",
    "                # Calculer le score Dice\n",
    "                pred = (torch.sigmoid(output) > 0.5).float()\n",
    "                dice = (2. * (pred * target).sum()) / (pred.sum() + target.sum() + 1e-6)\n",
    "                dice_scores.append(dice.item())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        mean_dice = np.mean(dice_scores)\n",
    "        \n",
    "        # Mise à jour du scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Sauvegarder le meilleur modèle\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': val_loss,\n",
    "            }, Config.MODELS_DIR / 'best_model.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}')\n",
    "        print(f'Dice Score: {mean_dice:.4f}')\n",
    "\n",
    "def visualize_batch(data, target, output, epoch, batch_idx):\n",
    "    \"\"\"Visualise les résultats pendant l'entraînement\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Prendre le premier exemple du batch\n",
    "        img = data[0, 0].cpu().numpy()\n",
    "        mask = target[0, 0].cpu().numpy()\n",
    "        pred = torch.sigmoid(output[0, 0]).cpu().numpy() > 0.5\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        axes[0].imshow(img, cmap='bone')\n",
    "        axes[0].set_title('Input')\n",
    "        \n",
    "        axes[1].imshow(mask, cmap='bone')\n",
    "        axes[1].set_title('Target')\n",
    "        \n",
    "        axes[2].imshow(pred, cmap='bone')\n",
    "        axes[2].set_title('Prediction')\n",
    "        \n",
    "        plt.suptitle(f'Epoch {epoch+1}, Batch {batch_idx}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_DIR = Path('./data')\n",
    "    OUTPUT_DIR = Path('./output')\n",
    "    MODELS_DIR = Path('./models')\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    @classmethod\n",
    "    def create_directories(cls):\n",
    "        for dir_path in [cls.DATA_DIR, cls.OUTPUT_DIR, cls.MODELS_DIR]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_masks(volume: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Crée des masques synthétiques pour l'entraînement initial\"\"\"\n",
    "    print(\"Creating synthetic masks...\")\n",
    "    print(f\"Input volume shape: {volume.shape}\")\n",
    "    \n",
    "    # Calculer les dimensions optimales\n",
    "    total_pixels = volume.shape[1]  # 262697\n",
    "    factors = []\n",
    "    for i in range(1, int(np.sqrt(total_pixels)) + 1):\n",
    "        if total_pixels % i == 0:\n",
    "            factors.append((i, total_pixels // i))\n",
    "    \n",
    "    print(\"Possible dimensions:\", factors)\n",
    "    \n",
    "    # Trouver les dimensions les plus proches de 512x512\n",
    "    target_size = 512\n",
    "    optimal_dims = min(factors, key=lambda x: abs(x[0] - target_size) + abs(x[1] - target_size))\n",
    "    height, width = optimal_dims\n",
    "    print(f\"Original dimensions: {height}x{width}\")\n",
    "    \n",
    "    # Redimensionner en 512x512\n",
    "    n_slices = volume.shape[2]\n",
    "    volume_reshaped = np.zeros((512, 512, n_slices))\n",
    "    \n",
    "    for i in range(n_slices):\n",
    "        # Redimensionner chaque tranche\n",
    "        slice_data = volume[0, :, i].reshape(height, width)\n",
    "        # Interpolation pour obtenir une image 512x512\n",
    "        slice_2d = cv2.resize(slice_data, (512, 512))\n",
    "        volume_reshaped[:, :, i] = slice_2d\n",
    "        \n",
    "        # Debug: afficher la première tranche\n",
    "        if i == 0:\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(slice_data, cmap='bone')\n",
    "            plt.title(f'Original ({height}x{width})')\n",
    "            plt.colorbar()\n",
    "            \n",
    "            plt.subplot(122)\n",
    "            plt.imshow(slice_2d, cmap='bone')\n",
    "            plt.title('Resized (512x512)')\n",
    "            plt.colorbar()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    print(f\"Reshaped volume: {volume_reshaped.shape}\")\n",
    "    \n",
    "    # Créer les masques\n",
    "    masks = np.zeros_like(volume_reshaped)\n",
    "    \n",
    "    for i in range(n_slices):\n",
    "        slice_data = volume_reshaped[:, :, i]\n",
    "        \n",
    "        # 1. Seuillage adaptatif\n",
    "        threshold = np.percentile(slice_data, 95)\n",
    "        binary = (slice_data > threshold).astype(np.uint8)\n",
    "        \n",
    "        # 2. Opérations morphologiques\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # 3. Trouver les contours\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # 4. Sélectionner le plus grand contour\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            \n",
    "            # 5. Créer un masque avec le contour\n",
    "            mask = np.zeros_like(slice_data)\n",
    "            cv2.drawContours(mask, [largest_contour], -1, 1, 2)\n",
    "            \n",
    "            masks[:, :, i] = mask\n",
    "            \n",
    "        # Debug: afficher quelques tranches\n",
    "        if i % 20 == 0:\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.subplot(131)\n",
    "            plt.imshow(slice_data, cmap='bone')\n",
    "            plt.title(f'Original Slice {i}')\n",
    "            plt.colorbar()\n",
    "            \n",
    "            plt.subplot(132)\n",
    "            plt.imshow(binary, cmap='bone')\n",
    "            plt.title('Binary Mask')\n",
    "            plt.colorbar()\n",
    "            \n",
    "            plt.subplot(133)\n",
    "            plt.imshow(masks[:, :, i], cmap='bone')\n",
    "            plt.title('Final Mask')\n",
    "            plt.colorbar()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return volume_reshaped, masks\n",
    "def visualize_masks(volume: np.ndarray, masks: np.ndarray, n_slices: int = 4):\n",
    "    \"\"\"Visualise les masques avec les images originales\"\"\"\n",
    "    fig, axes = plt.subplots(2, n_slices, figsize=(20, 10))\n",
    "    step = volume.shape[2] // n_slices\n",
    "    \n",
    "    for i in range(n_slices):\n",
    "        idx = i * step\n",
    "        \n",
    "        # Image originale\n",
    "        axes[0, i].imshow(volume[:, :, idx], cmap='bone')\n",
    "        axes[0, i].set_title(f'Original Slice {idx}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Masque\n",
    "        axes[1, i].imshow(masks[:, :, idx], cmap='bone')\n",
    "        axes[1, i].set_title(f'Mask Slice {idx}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "class BoneDataset(Dataset):\n",
    "    \"\"\"Dataset pour les images CT et leurs masques\"\"\"\n",
    "    def __init__(self, volume: np.ndarray, masks: np.ndarray, transform=None):\n",
    "        self.volume = volume\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "        \n",
    "        print(f\"Dataset initialized with volume shape: {volume.shape}\")\n",
    "        print(f\"Masks shape: {masks.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.volume.shape[2]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.volume[:, :, idx]\n",
    "        mask = self.masks[:, :, idx]\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return (torch.from_numpy(image).float().unsqueeze(0),\n",
    "                torch.from_numpy(mask).float().unsqueeze(0))\n",
    "                \n",
    "def create_dataloaders(volume: np.ndarray, masks: np.ndarray, \n",
    "                      train_ratio: float = 0.8, batch_size: int = 8):\n",
    "    \"\"\"Crée les dataloaders pour l'entraînement\"\"\"\n",
    "    \n",
    "    # Augmentation pour l'entraînement\n",
    "    train_transform = A.Compose([\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.5),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "            A.OpticalDistortion(distort_limit=0.3, p=0.5),\n",
    "        ], p=0.3),\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.RandomGamma(p=0.5),\n",
    "        ], p=0.3),\n",
    "    ])\n",
    "\n",
    "    # Diviser en train/val\n",
    "    n_slices = volume.shape[2]\n",
    "    n_train = int(n_slices * train_ratio)\n",
    "    \n",
    "    train_volume = volume[:, :, :n_train]\n",
    "    train_masks = masks[:, :, :n_train]\n",
    "    val_volume = volume[:, :, n_train:]\n",
    "    val_masks = masks[:, :, n_train:]\n",
    "\n",
    "    print(f\"\\nTrain volume shape: {train_volume.shape}\")\n",
    "    print(f\"Val volume shape: {val_volume.shape}\")\n",
    "\n",
    "    # Créer les datasets\n",
    "    train_dataset = BoneDataset(train_volume, train_masks, transform=train_transform)\n",
    "    val_dataset = BoneDataset(val_volume, val_masks)\n",
    "\n",
    "    # Créer les dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n",
    "def visualize_augmentations(dataset, n_samples=3):\n",
    "    \"\"\"Visualise les augmentations de données\"\"\"\n",
    "    fig, axes = plt.subplots(n_samples, 3, figsize=(15, 5*n_samples))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Obtenir un échantillon original\n",
    "        image, mask = dataset[i]\n",
    "        image = image.squeeze().numpy()\n",
    "        mask = mask.squeeze().numpy()\n",
    "        \n",
    "        # Appliquer l'augmentation\n",
    "        if dataset.transform:\n",
    "            augmented = dataset.transform(image=image, mask=mask)\n",
    "            aug_image = augmented['image']\n",
    "            aug_mask = augmented['mask']\n",
    "        else:\n",
    "            aug_image = image\n",
    "            aug_mask = mask\n",
    "        \n",
    "        # Afficher\n",
    "        axes[i, 0].imshow(image, cmap='bone')\n",
    "        axes[i, 0].set_title('Original')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(aug_image, cmap='bone')\n",
    "        axes[i, 1].set_title('Augmented')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(aug_mask, cmap='bone')\n",
    "        axes[i, 2].set_title('Augmented Mask')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self._block(in_channels, 64)\n",
    "        self.enc2 = self._block(64, 128)\n",
    "        self.enc3 = self._block(128, 256)\n",
    "        self.enc4 = self._block(256, 512)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self._block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec4 = self._block(1024, 512)\n",
    "        self.dec3 = self._block(512, 256)\n",
    "        self.dec2 = self._block(256, 128)\n",
    "        self.dec1 = self._block(128, 64)\n",
    "        \n",
    "        # Final conv\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Upsampling\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.pool(enc1))\n",
    "        enc3 = self.enc3(self.pool(enc2))\n",
    "        enc4 = self.enc4(self.pool(enc3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool(enc4))\n",
    "        \n",
    "        # Decoder\n",
    "        dec4 = self.dec4(torch.cat([self.up4(bottleneck), enc4], 1))\n",
    "        dec3 = self.dec3(torch.cat([self.up3(dec4), enc3], 1))\n",
    "        dec2 = self.dec2(torch.cat([self.up2(dec3), enc2], 1))\n",
    "        dec1 = self.dec1(torch.cat([self.up1(dec2), enc1], 1))\n",
    "        \n",
    "        return self.final_conv(dec1)\n",
    "\n",
    "    def _block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "def load_and_display_ct(dicom_dir: Path, slice_idx: int = 0):\n",
    "    \"\"\"Charge et affiche une tranche du CT scan\"\"\"\n",
    "    print(f\"Loading DICOM series from {dicom_dir}...\")\n",
    "    \n",
    "    # Trouver tous les fichiers DICOM\n",
    "    dicom_files = sorted(dicom_dir.glob('phalanx*.dcm'))\n",
    "    if not dicom_files:\n",
    "        raise FileNotFoundError(f\"No DICOM files found in {dicom_dir}\")\n",
    "    \n",
    "    print(f\"Found {len(dicom_files)} files\")\n",
    "    \n",
    "    # Charger la tranche spécifiée\n",
    "    slice_data = pydicom.dcmread(str(dicom_files[slice_idx]), force=True)\n",
    "    raw_data = slice_data.pixel_array\n",
    "    \n",
    "    print(f\"\\nSlice {slice_idx} info:\")\n",
    "    print(f\"Shape: {raw_data.shape}\")\n",
    "    print(f\"Data type: {raw_data.dtype}\")\n",
    "    print(f\"Value range: [{raw_data.min()}, {raw_data.max()}]\")\n",
    "    \n",
    "    # Normaliser les données pour l'affichage\n",
    "    normalized_data = (raw_data - raw_data.min()) / (raw_data.max() - raw_data.min())\n",
    "    \n",
    "    # Créer une figure avec plusieurs vues\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    \n",
    "    # 1. Image originale\n",
    "    im1 = axes[0, 0].imshow(raw_data, cmap='bone')\n",
    "    axes[0, 0].set_title('Image originale')\n",
    "    plt.colorbar(im1, ax=axes[0, 0])\n",
    "    \n",
    "    # 2. Image normalisée\n",
    "    im2 = axes[0, 1].imshow(normalized_data, cmap='bone')\n",
    "    axes[0, 1].set_title('Image normalisée')\n",
    "    plt.colorbar(im2, ax=axes[0, 1])\n",
    "    \n",
    "    # 3. Histogramme des valeurs originales\n",
    "    axes[1, 0].hist(raw_data.ravel(), bins=100, color='blue', alpha=0.7)\n",
    "    axes[1, 0].set_title('Distribution des valeurs originales')\n",
    "    axes[1, 0].set_xlabel('Intensité')\n",
    "    axes[1, 0].set_ylabel('Fréquence')\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # 4. Histogramme des valeurs normalisées\n",
    "    axes[1, 1].hist(normalized_data.ravel(), bins=100, color='green', alpha=0.7)\n",
    "    axes[1, 1].set_title('Distribution des valeurs normalisées')\n",
    "    axes[1, 1].set_xlabel('Intensité normalisée')\n",
    "    axes[1, 1].set_ylabel('Fréquence')\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Afficher les profils d'intensité\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n",
    "    \n",
    "    # Profil horizontal (milieu de l'image)\n",
    "    middle_row = raw_data.shape[0] // 2\n",
    "    ax1.plot(raw_data[middle_row, :])\n",
    "    ax1.set_title(f'Profil horizontal (ligne {middle_row})')\n",
    "    ax1.set_xlabel('Position X')\n",
    "    ax1.set_ylabel('Intensité')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Profil vertical (milieu de l'image)\n",
    "    middle_col = raw_data.shape[1] // 2\n",
    "    ax2.plot(raw_data[:, middle_col])\n",
    "    ax2.set_title(f'Profil vertical (colonne {middle_col})')\n",
    "    ax2.set_xlabel('Position Y')\n",
    "    ax2.set_ylabel('Intensité')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return raw_data, normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage des images brutes...\n",
      "\n",
      "Erreur: name 'display_raw_images' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_46734/866377687.py\", line 104, in <module>\n",
      "    first_image = display_raw_images(data_dir, n_slices=4)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'display_raw_images' is not defined\n"
     ]
    }
   ],
   "source": [
    "def enhance_image(image):\n",
    "    \"\"\"Améliore la qualité de l'image avec plusieurs techniques\"\"\"\n",
    "    # Normalisation initiale\n",
    "    normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_img = clahe.apply(normalized.astype(np.uint8))\n",
    "    \n",
    "    # Débruitage\n",
    "    denoised = cv2.fastNlMeansDenoising(clahe_img)\n",
    "    \n",
    "    # Amélioration des bords\n",
    "    kernel = np.array([[-1,-1,-1],\n",
    "                      [-1, 9,-1],\n",
    "                      [-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(denoised, -1, kernel)\n",
    "    \n",
    "    return normalized, clahe_img, denoised, sharpened\n",
    "\n",
    "def analyze_enhanced_image(image):\n",
    "    \"\"\"Analyse détaillée de l'image avec différentes améliorations\"\"\"\n",
    "    # Appliquer les améliorations\n",
    "    normalized, clahe_img, denoised, sharpened = enhance_image(image)\n",
    "    \n",
    "    # Créer une grande figure\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Image originale\n",
    "    plt.subplot(331)\n",
    "    plt.imshow(image, cmap='bone')\n",
    "    plt.title('Image originale')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 2. Image normalisée\n",
    "    plt.subplot(332)\n",
    "    plt.imshow(normalized, cmap='bone')\n",
    "    plt.title('Normalisée')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 3. CLAHE\n",
    "    plt.subplot(333)\n",
    "    plt.imshow(clahe_img, cmap='bone')\n",
    "    plt.title('CLAHE')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 4. Débruitage\n",
    "    plt.subplot(334)\n",
    "    plt.imshow(denoised, cmap='bone')\n",
    "    plt.title('Débruitée')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 5. Accentuation des bords\n",
    "    plt.subplot(335)\n",
    "    plt.imshow(sharpened, cmap='bone')\n",
    "    plt.title('Bords accentués')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 6. Détection de contours (Sobel)\n",
    "    sobelx = cv2.Sobel(normalized, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(normalized, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    plt.subplot(336)\n",
    "    plt.imshow(sobel, cmap='bone')\n",
    "    plt.title('Sobel')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 7. Seuillage adaptatif\n",
    "    thresh = cv2.adaptiveThreshold(normalized.astype(np.uint8), 255,\n",
    "                                 cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                 cv2.THRESH_BINARY, 11, 2)\n",
    "    plt.subplot(337)\n",
    "    plt.imshow(thresh, cmap='bone')\n",
    "    plt.title('Seuillage adaptatif')\n",
    "    \n",
    "    # 8. Gradient morphologique\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    gradient = cv2.morphologyEx(normalized.astype(np.uint8), \n",
    "                              cv2.MORPH_GRADIENT, kernel)\n",
    "    plt.subplot(338)\n",
    "    plt.imshow(gradient, cmap='bone')\n",
    "    plt.title('Gradient morphologique')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 9. Superposition contours sur original\n",
    "    overlay = cv2.addWeighted(normalized.astype(np.uint8), 0.7,\n",
    "                            gradient, 0.3, 0)\n",
    "    plt.subplot(339)\n",
    "    plt.imshow(overlay, cmap='bone')\n",
    "    plt.title('Superposition')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return normalized, clahe_img, denoised, sharpened\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = Path('./data/dicom_series')\n",
    "    \n",
    "    try:\n",
    "        # 1. Afficher quelques images brutes\n",
    "        print(\"Affichage des images brutes...\")\n",
    "        first_image = display_raw_images(data_dir, n_slices=4)\n",
    "        \n",
    "        # 2. Analyser l'image améliorée\n",
    "        print(\"\\nAnalyse détaillée avec améliorations...\")\n",
    "        normalized, clahe_img, denoised, sharpened = analyze_enhanced_image(first_image)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nErreur: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "def display_raw_images(dicom_dir: Path, n_slices: int = 4):\n",
    "    \"\"\"Affiche quelques images brutes du dossier\"\"\"\n",
    "    print(f\"Loading images from {dicom_dir}...\")\n",
    "    \n",
    "    # Trouver tous les fichiers humerus\n",
    "    image_files = sorted(dicom_dir.glob('humerus*.dcm'))\n",
    "    if not image_files:\n",
    "        raise FileNotFoundError(f\"No humerus DICOM files found in {dicom_dir}\")\n",
    "    \n",
    "    print(f\"Found {len(image_files)} files\")\n",
    "    \n",
    "    # Sélectionner quelques images réparties uniformément\n",
    "    step = len(image_files) // n_slices\n",
    "    selected_files = [image_files[i * step] for i in range(n_slices)]\n",
    "    \n",
    "    # Créer une figure avec n_slices sous-plots\n",
    "    fig, axes = plt.subplots(1, n_slices, figsize=(20, 5))\n",
    "    \n",
    "    for i, file_path in enumerate(selected_files):\n",
    "        try:\n",
    "            # Lire le fichier DICOM\n",
    "            dicom_data = pydicom.dcmread(str(file_path), force=True)\n",
    "            \n",
    "            # Extraire les données pixel\n",
    "            image = dicom_data.pixel_array\n",
    "            \n",
    "            print(f\"\\nFile: {file_path.name}\")\n",
    "            print(f\"Image shape: {image.shape}\")\n",
    "            print(f\"Data type: {image.dtype}\")\n",
    "            print(f\"Value range: [{image.min()}, {image.max()}]\")\n",
    "            print(f\"Mean value: {image.mean():.2f}\")\n",
    "            \n",
    "            # Normaliser pour l'affichage\n",
    "            image_float = image.astype(float)\n",
    "            # Utiliser les percentiles pour éviter les valeurs extrêmes\n",
    "            p1, p99 = np.percentile(image_float, (1, 99))\n",
    "            image_normalized = np.clip((image_float - p1) / (p99 - p1), 0, 1)\n",
    "            \n",
    "            # Convertir en uint8 pour CLAHE\n",
    "            image_uint8 = (image_normalized * 255).astype(np.uint8)\n",
    "            \n",
    "            # Améliorer le contraste avec CLAHE\n",
    "            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "            enhanced = clahe.apply(image_uint8)\n",
    "            \n",
    "            # Afficher l'image\n",
    "            im = axes[i].imshow(enhanced, cmap='bone')\n",
    "            axes[i].set_title(f'Slice {i*step}\\n{image.shape[0]}x{image.shape[1]}')\n",
    "            axes[i].axis('off')\n",
    "            plt.colorbar(im, ax=axes[i])\n",
    "            \n",
    "            # Afficher l'histogramme\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.hist(image.ravel(), bins=100, color='blue', alpha=0.7)\n",
    "            plt.title(f'Distribution des intensités - Slice {i*step}')\n",
    "            plt.xlabel('Intensité')\n",
    "            plt.ylabel('Fréquence')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "def analyze_slice(image):\n",
    "    \"\"\"Analyse détaillée d'une tranche\"\"\"\n",
    "    # Créer une figure pour l'analyse\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # 1. Image originale\n",
    "    plt.subplot(231)\n",
    "    plt.imshow(image, cmap='bone')\n",
    "    plt.title('Original')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 2. Histogramme\n",
    "    plt.subplot(232)\n",
    "    plt.hist(image.ravel(), bins=50, color='blue', alpha=0.7)\n",
    "    plt.title('Histogramme')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 3. CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    clahe_img = clahe.apply(image.astype(np.uint8))\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(clahe_img, cmap='bone')\n",
    "    plt.title('CLAHE')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 4. Détection de contours\n",
    "    edges = cv2.Canny(image.astype(np.uint8), 50, 150)\n",
    "    plt.subplot(234)\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.title('Contours')\n",
    "    \n",
    "    # 5. Segmentation par seuillage adaptatif\n",
    "    thresh = cv2.adaptiveThreshold(image.astype(np.uint8), 255,\n",
    "                                 cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                 cv2.THRESH_BINARY, 11, 2)\n",
    "    plt.subplot(235)\n",
    "    plt.imshow(thresh, cmap='gray')\n",
    "    plt.title('Seuillage adaptatif')\n",
    "    \n",
    "    # 6. Superposition contours sur original\n",
    "    overlay = cv2.addWeighted(image.astype(np.uint8), 0.7,\n",
    "                            edges, 0.3, 0)\n",
    "    plt.subplot(236)\n",
    "    plt.imshow(overlay, cmap='bone')\n",
    "    plt.title('Superposition')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage des images brutes...\n",
      "Loading images from data/dicom_series...\n",
      "\n",
      "Erreur: No humerus DICOM files found in data/dicom_series\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_46734/1986210829.py\", line 7, in <module>\n",
      "    enhanced_image = display_raw_images(data_dir, n_slices=4)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_46734/1238474881.py\", line 13, in display_raw_images\n",
      "    raise FileNotFoundError(f\"No humerus DICOM files found in {dicom_dir}\")\n",
      "FileNotFoundError: No humerus DICOM files found in data/dicom_series\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = Path('./data/dicom_series')\n",
    "    \n",
    "    try:\n",
    "        # 1. Afficher les tranches\n",
    "        print(\"Affichage des images brutes...\")\n",
    "        enhanced_image = display_raw_images(data_dir, n_slices=4)\n",
    "        \n",
    "        # 2. Analyser une tranche en détail\n",
    "        print(\"\\nAnalyse détaillée d'une tranche...\")\n",
    "        analyze_slice(enhanced_image)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nErreur: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
